<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.11.6" />
<title>tff.convert.helpers API documentation</title>
<meta name="description" content="" />
<!-- integrity SRI from https://cdnjs.com/libraries/10up-sanitize.css/11.0.1 -->
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
integrity="sha512-kcbluZFacWN57NgWZ4aH6eUMBEaTyErFhIFD3y5qYZbKuuyImH0K/AKsBbfXlivh2z5C+3IDTIhI11YmKomzmA=="
crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
integrity="sha512-uVeAgzAmieLUTGba0qr9vXQgVD7fko2kcbYIKIraXUIDg9iJLxveTFUrg3DJhqn3cAf3HFDbgmhq0eGko5wEAA=="
crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tff.convert.helpers</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L1-L883" class="git-link">Browse git</a>
</summary>
<pre><code class="python">import re
from textwrap import dedent

from tf.core.generic import AttrDict
from tf.core.helpers import console
from tf.core.files import fileExists, readJson, readYaml, stripExt, fileOpen, dirExists


PRE = &#34;pre&#34;
ZWSP = &#34;\u200b&#34;  # zero-width space

NODE = &#34;node&#34;
FOLDER = &#34;folder&#34;
FILE = &#34;file&#34;
PAGE = &#34;page&#34;
LINE = &#34;line&#34;
LN = &#34;ln&#34;
REGION = &#34;region&#34;
DOC = &#34;doc&#34;
CHAPTER = &#34;chapter&#34;
CHUNK = &#34;chunk&#34;

XNEST = &#34;xnest&#34;
TNEST = &#34;tnest&#34;
TSIB = &#34;tsiblings&#34;
SLOT = &#34;slot&#34;
WORD = &#34;word&#34;
CHAR = &#34;char&#34;
TOKEN = &#34;token&#34;
T = &#34;t&#34;


LINE_MODELS = dict(
    I=dict(),
    II=dict(
        element=(str, &#34;p&#34;),
        nodeType=(str, LN),
    ),
)


LINE_MODEL_DEFAULT = &#34;I&#34;

PAGE_MODELS = dict(
    I=dict(),
    II=dict(
        keepPb=(bool, False),
        element=(str, &#34;div&#34;),
        attributes=(dict, {}),
        pbAtTop=(bool, True),
        nodeType=(str, PAGE),
    ),
)


PAGE_MODEL_DEFAULT = &#34;I&#34;

SECTION_MODELS = dict(
    I=dict(
        levels=(list, [FOLDER, FILE, CHUNK]),
        drillDownDivs=(bool, True),
        backMatter=(str, &#34;backmatter&#34;),
    ),
    II=dict(
        levels=(list, [CHAPTER, CHUNK]),
        element=(str, &#34;head&#34;),
        attributes=(dict, {}),
    ),
    III=dict(
        levels=(list, [FILE, CHAPTER, CHUNK]),
        element=(str, &#34;head&#34;),
        attributes=(dict, {}),
    ),
)
&#34;&#34;&#34;Models for sections.

A section is a part of the corpus that is defined by a set of files,
or by elements within a single TEI source file.

A model
&#34;&#34;&#34;


SECTION_MODEL_DEFAULT = &#34;I&#34;
&#34;&#34;&#34;Default model for sections.
&#34;&#34;&#34;

CM_LIT = &#34;literal&#34;
&#34;&#34;&#34;The value is taken literally from a TEI attribute.

Code `tei`, since there is a 1-1 correspondence with the TEI source.
&#34;&#34;&#34;

CM_LITP = &#34;literal-processed&#34;
&#34;&#34;&#34;The value results from straightforward processing of material in the TEI.

Code `tei`, since there is a direct correspondence with the TEI source.

*Straightforward* means: by taking into account the semantics of XML.

Examples:

*   Generated white-space based on whether elements are pure or mixed;
*   Edges between parent and child elements, or sibling elements.
&#34;&#34;&#34;

CM_LITC = &#34;literal-composed&#34;
&#34;&#34;&#34;The value is results from more intricate processing of material in the TEI.

*More intricate means*: we derive data that goes beyond pure XML syntax.

Examples:

*   The values of the `rend` attributes are translated into `rend_`*value* features;
*   Adding features `is_meta` (being inside the TEI-header) and `is_note`
    (being inside a note);
*   The feature that gives the content of a (character) slot;
*   Decomposing strings into words material and after-word material.

Code `tf`, since this is for the benefit of the resulting TF dataset.
&#34;&#34;&#34;

CM_PROV = &#34;provided&#34;
&#34;&#34;&#34;The value is added by the conversion to TF w.r.t. the material in the TEI.

Examples:

*   Slots in empty elements, in order to anchor the element to the text sequence;
*   Section levels, based on the folder and file that the TEI source is in;
*   A section level within the TEI, defined from several elements and the way they
    are nested;

Code `tf`, since this is for the benefit of the resulting TF dataset.
&#34;&#34;&#34;

CM_NLP = &#34;nlp-generated&#34;
&#34;&#34;&#34;The value is added by an NLP pipeline w.r.t. the material in the TEI.

Code `nlp`, since this comes from third party software.

Examples:

*   The feature `nsent` which gives the sentence number in the corpus.
    Sentences are not encoded in the TEI, but detected by an NLP program such as Spacy.
&#34;&#34;&#34;

CONVERSION_METHODS = {
    CM_LIT: &#34;tei&#34;,
    CM_LITP: &#34;tei&#34;,
    CM_LITC: &#34;tf&#34;,
    CM_PROV: &#34;tf&#34;,
    CM_NLP: &#34;nlp&#34;,
}
&#34;&#34;&#34;Information about the conversion.

When we produce TF features, we specify a bit of information in the feature
metadata as how we arrived at the specific value.

That information ends up in two keys:

*   `conversionMethod`: with values any of:
    *   `CM_LIT`
    *   `CM_LITP`
    *   `CM_LITC`
    *   `CM_PROV`
    *   `CM_NLP`
*   `conversionCode`: the value is derived from `conversionMethod` by looking it
    up in this table. These values can be used to qualify the name of the attribute
    for further processing.

    For example, if you have a feature `n` that originates literally from the TEI,
    you could pass it on as `tei:n`.

    But if you have a feature `chapter` that is provided by the conversion,
    you could pass it on as `tf:chapter`.

    This passing on is a matter of other software, that takes the generated TF as
    input and processes it further, e.g. as annotations.

!!! note &#34;More methods and codes&#34;

The TEI conversion is customizable by providing your own methods to several hooks
in the program. These hooks may generate extra features, which you can give metadata
in the `config/tei.yml` file close to the `programs/tei.py` file where you
define the custom functions.

It is advised to state appropriate values for the `conversionMethod` and
`conversionCode` fields of these features.

Examples:

*   A feature `country` is derived from specific elements in the TEI Header, and
    defined for nodes of type `letter`.
    This happens in order to support the software of Team Text that shows the
    text on a webpage.

    In such a case you could define

    *   `conversionMethod=&#34;derived&#34;
    *   `conversionCode=&#34;tt&#34;
&#34;&#34;&#34;


TOKEN_RE = re.compile(r&#34;&#34;&#34;\w+|\W&#34;&#34;&#34;)
NUMBER_RE = re.compile(
    r&#34;&#34;&#34;
    ^
    [0-9]+
    (?:
        [.,]
        [0-9]+
    )*
    $
&#34;&#34;&#34;,
    re.X,
)

W_BEFORE = re.compile(r&#34;&#34;&#34;^\s+&#34;&#34;&#34;)
W_AFTER = re.compile(r&#34;&#34;&#34;\s+$&#34;&#34;&#34;)


def getWhites(text):
    match = W_BEFORE.match(text)
    if match:
        before = match.group(0)
        rest = text[len(before) :]
    else:
        before = &#34;&#34;
        rest = text
    match = W_AFTER.search(rest)
    if match:
        after = match.group(0)
        material = rest[0 : -len(after)]
    else:
        after = &#34;&#34;
        material = rest
    return (&#34; &#34; if before else &#34;&#34;, material, &#34; &#34; if after else &#34;&#34;)


def tokenize(line):
    tokens = []

    for word in line.split():
        ts = (
            [[word, &#34;&#34;]]
            if NUMBER_RE.match(word)
            else [[t, &#34;&#34;] for t in TOKEN_RE.findall(word)]
        )
        if len(ts):
            ts[-1][-1] = &#34; &#34;
        tokens.extend(ts)

    if len(tokens):
        tokens[-1][-1] = &#34;&#34;
    return tuple(tokens)


def repTokens(tokens):
    text = []
    for t, space in tokens:
        text.append(f&#34;‹{t}›{space}&#34;)
    return &#34;&#34;.join(text)


def checkModel(kind, thisModel, verbose):
    modelDefault = (
        LINE_MODEL_DEFAULT
        if kind == LINE
        else PAGE_MODEL_DEFAULT if kind == PAGE else SECTION_MODEL_DEFAULT
    )
    modelSpecs = (
        LINE_MODELS if kind == LINE else PAGE_MODELS if kind == PAGE else SECTION_MODELS
    )

    if thisModel is None:
        model = modelDefault
        if verbose == 1:
            console(f&#34;WARNING: No {kind} model specified. Assuming model {model}.&#34;)
        properties = {k: v[1] for (k, v) in modelSpecs[model].items()}
        return dict(model=model, properties=properties)

    if type(thisModel) is str:
        if thisModel in modelSpecs:
            thisModel = dict(model=thisModel)
        else:
            console(f&#34;ERROR: unknown {kind} model: {thisModel}&#34;)
            return False

    elif type(thisModel) is not dict:
        console(f&#34;ERROR: {kind} model must be a dict. You passed a {type(thisModel)}&#34;)
        return False

    model = thisModel.get(&#34;model&#34;, None)

    if model is None:
        model = modelDefault
        if verbose == 1:
            console(f&#34;WARNING: No {kind} model specified. Assuming model {model}.&#34;)
        thisModel[&#34;model&#34;] = model

    if model not in modelSpecs:
        console(f&#34;WARNING: unknown {kind} model: {thisModel}&#34;)
        return False

    if verbose &gt;= 0:
        console(f&#34;{kind} model is {model}&#34;)

    properties = {k: v for (k, v) in thisModel.items() if k != &#34;model&#34;}
    modelProperties = modelSpecs[model]

    good = True
    delKeys = []

    for k, v in properties.items():
        if k not in modelProperties:
            console(f&#34;WARNING: ignoring unknown {kind} model property {k}={v}&#34;)
            delKeys.append(k)
        elif type(v) is not modelProperties[k][0]:
            console(
                f&#34;ERROR: {kind} property {k} should have type {modelProperties[k][0]}&#34;
                f&#34; but {v} has type {type(v)}&#34;
            )
            good = False
    if good:
        for k in delKeys:
            del properties[k]

    for k, v in modelProperties.items():
        if k not in properties:
            if verbose == 1:
                console(
                    f&#34;WARNING: {kind} model property {k} not specified, &#34;
                    f&#34;taking default {v[1]}&#34;
                )
            properties[k] = v[1]

    if not good:
        return False

    return dict(model=model, properties=properties)


def matchModel(properties, tag, atts):
    if tag == properties[&#34;element&#34;]:
        criticalAtts = properties[&#34;attributes&#34;]
        match = True

        for k, cVal in criticalAtts.items():
            aVal = atts.get(k, None)

            thisNoMatch = (
                all(aVal != cV for cV in cVal)
                if type(cVal) in {list, tuple, set}
                else aVal != cVal
            )
            if thisNoMatch:
                match = False
                break
        return match


def setUp(kind):
    helpText = f&#34;&#34;&#34;
    Convert {kind} to TF.

    There are also commands to check the {kind} and to load the resulting TF.&#34;&#34;&#34;

    taskSpec = dict(
        check=&#34;reports on the elements in the source&#34;,
        convert=f&#34;converts {kind} to TF&#34;,
        load=&#34;loads the generated TF&#34;,
        app=&#34;configures the TF app for the result&#34;,
        apptoken=&#34;modifies the TF app to make it token- instead of character-based&#34;,
        browse=&#34;starts the TF browser on the result&#34;,
    )

    paramSpec = {
        &#34;tf&#34;: (
            (
                &#34;0 or latest: update latest version;\n\t\t&#34;
                &#34;1 2 3: increase major, intermediate, minor TF version;\n\t\t&#34;
                &#34;rest: explicit version.&#34;
            ),
            &#34;latest&#34;,
        ),
        &#34;sourceBase&#34;: (
            (&#34;empty: refDir/{kind.lower()};\n\t\t&#34; &#34;any directory of choice.&#34;),
            &#34;&#34;,
        ),
        &#34;reportDir&#34;: (
            (&#34;empty: refDir/report;\n\t\t&#34; &#34;any directory of choice.&#34;),
            &#34;&#34;,
        ),
        kind.lower(): (
            (
                &#34;0 or latest: latest version;\n\t\t&#34;
                &#34;-1 -2 etc: previous version, before previous, ...;\n\t\t&#34;
                &#34;1 2 etc: first version, second version, ...;\n\t\t&#34;
                &#34;rest: explicit version.&#34;
            ),
            &#34;latest&#34;,
        ),
        &#34;validate&#34;: (
            &#34;Whether to validate the XML input&#34;,
            True,
        ),
    }

    flagSpec = dict(
        verbose=(&#34;Produce less or more progress and reporting messages&#34;, -1, 3),
        doc=(&#34;Do only this document&#34;, None, 0),
    )
    return (helpText, taskSpec, paramSpec, flagSpec)


def tweakTrans(
    template,
    procins,
    wordAsSlot,
    tokenAsSlot,
    charAsSlot,
    parentEdges,
    siblingEdges,
    tokenBased,
    sectionModel,
    sectionProperties,
    rendDesc,
    extra,
):
    if wordAsSlot:
        slot = WORD
        slotc = &#34;Word&#34;
        slotf = &#34;words&#34;
        xslot = &#34;`word`&#34;
    elif charAsSlot:
        slotc = &#34;Char&#34;
        slot = CHAR
        slotf = &#34;characters&#34;
        xslot = &#34;`char` and `word`&#34;
    elif tokenAsSlot or True:
        slotc = &#34;Token&#34;
        slot = T
        slotf = &#34;tokens&#34;
        xslot = &#34;`t` and `word`&#34;

    if parentEdges:
        hasParent = &#34;Yes&#34;
    else:
        hasParent = &#34;No&#34;

    if siblingEdges:
        hasSibling = &#34;Yes&#34;
    else:
        hasSibling = &#34;No&#34;

    if tokenBased:
        slot = TOKEN
        slotc = &#34;Token&#34;
        slotf = &#34;tokens&#34;
        xslot = &#34;`token`&#34;
        tokenGen = dedent(
            &#34;&#34;&#34;
            Tokens and sentence boundaries have been generated by a Natural Language
            Pipeline, such as Spacy.
            &#34;&#34;&#34;
        )
        tokenWord = &#34;token&#34;
        hasToken = &#34;Yes&#34;
    else:
        tokenGen = &#34;&#34;
        tokenWord = &#34;word&#34;
        hasToken = &#34;No&#34;

    if extra:
        hasExtra = &#34;Yes&#34;
    else:
        hasExtra = &#34;No&#34;

    if procins:
        doProcins = &#34;Yes&#34;
    else:
        doProcins = &#34;No&#34;

    levelNames = sectionProperties[&#34;levels&#34;]

    if sectionModel == &#34;II&#34;:
        nLevels = &#34;2&#34;
        chapterSection = levelNames[0]
        chunkSection = levelNames[1]
        head = sectionProperties[&#34;element&#34;]
        attributes = sectionProperties[&#34;attributes&#34;]
        propertiesRaw = repr(sectionProperties)
        properties = (
            &#34;&#34;.join(
                f&#34;\t*\t`{att}` = `{val}`\n&#34; for (att, val) in sorted(attributes.items())
            )
            if attributes
            else &#34;\t*\t*no attribute properties*\n&#34;
        )
    elif sectionModel == &#34;III&#34;:
        nLevels = &#34;3&#34;
        fileSection = levelNames[0]
        chapterSection = levelNames[1]
        chunkSection = levelNames[2]
        head = sectionProperties[&#34;element&#34;]
        attributes = sectionProperties[&#34;attributes&#34;]
        propertiesRaw = repr(sectionProperties)
        properties = (
            &#34;&#34;.join(
                f&#34;\t*\t`{att}` = `{val}`\n&#34; for (att, val) in sorted(attributes.items())
            )
            if attributes
            else &#34;\t*\t*no attribute properties*\n&#34;
        )
    else:
        nLevels = &#34;3&#34;
        folderSection = levelNames[0]
        fileSection = levelNames[1]
        chunkSection = levelNames[2]

    rendDescStr = &#34;\n&#34;.join(
        f&#34;`{val}` | {desc}&#34; for (val, desc) in sorted(rendDesc.items())
    )
    modelKeepRe = re.compile(rf&#34;«(?:begin|end)Model{sectionModel}»&#34;)
    modelRemoveRe = re.compile(r&#34;«beginModel([^»]+)».*?«endModel\1»&#34;, re.S)
    slotKeepRe = re.compile(rf&#34;«(?:begin|end)Slot{slot}»&#34;)
    slotRemoveRe = re.compile(r&#34;«beginSlot([^»]+)».*?«endSlot\1»&#34;, re.S)
    tokenKeepRe = re.compile(rf&#34;«(?:begin|end)Token{hasToken}»&#34;)
    tokenRemoveRe = re.compile(r&#34;«beginToken([^»]+)».*?«endToken\1»&#34;, re.S)
    parentKeepRe = re.compile(rf&#34;«(?:begin|end)Parent{hasParent}»&#34;)
    parentRemoveRe = re.compile(r&#34;«beginParent([^»]+)».*?«endParent\1»&#34;, re.S)
    siblingKeepRe = re.compile(rf&#34;«(?:begin|end)Sibling{hasSibling}»&#34;)
    siblingRemoveRe = re.compile(r&#34;«beginSibling([^»]+)».*?«endSibling\1»&#34;, re.S)
    extraKeepRe = re.compile(rf&#34;«(?:begin|end)Extra{hasExtra}»&#34;)
    extraRemoveRe = re.compile(r&#34;«beginExtra([^»]+)».*?«endToken\1»&#34;, re.S)
    procinsKeepRe = re.compile(rf&#34;«(?:begin|end)Procins{doProcins}»&#34;)
    procinsRemoveRe = re.compile(r&#34;«beginProcins([^»]+)».*?«endToken\1»&#34;, re.S)

    skipVars = re.compile(r&#34;«[^»]+»&#34;)

    text = (
        template.replace(&#34;«slot»&#34;, slot)
        .replace(&#34;«Slot»&#34;, slotc)
        .replace(&#34;«slotf»&#34;, slotf)
        .replace(&#34;«char and word»&#34;, xslot)
        .replace(&#34;«tokenWord»&#34;, tokenWord)
        .replace(&#34;«token generation»&#34;, tokenGen)
        .replace(&#34;«nLevels»&#34;, nLevels)
        .replace(&#34;«sectionModel»&#34;, sectionModel)
        .replace(&#34;«rendDesc»&#34;, rendDescStr)
        .replace(&#34;«extraFeatures»&#34;, extra)
    )
    if sectionModel == &#34;II&#34;:
        text = (
            text.replace(&#34;«head»&#34;, head)
            .replace(&#34;«properties»&#34;, properties)
            .replace(&#34;«propertiesRaw»&#34;, propertiesRaw)
            .replace(&#34;«chapter»&#34;, chapterSection)
            .replace(&#34;«chunk»&#34;, chunkSection)
        )
    elif sectionModel == &#34;III&#34;:
        text = (
            text.replace(&#34;«file»&#34;, fileSection)
            .replace(&#34;«head»&#34;, head)
            .replace(&#34;«properties»&#34;, properties)
            .replace(&#34;«propertiesRaw»&#34;, propertiesRaw)
            .replace(&#34;«chapter»&#34;, chapterSection)
            .replace(&#34;«chunk»&#34;, chunkSection)
        )
    else:
        text = (
            text.replace(&#34;«folder»&#34;, folderSection)
            .replace(&#34;«file»&#34;, fileSection)
            .replace(&#34;«chunk»&#34;, chunkSection)
        )

    text = parentKeepRe.sub(&#34;&#34;, text)
    text = parentRemoveRe.sub(&#34;&#34;, text)
    text = siblingKeepRe.sub(&#34;&#34;, text)
    text = siblingRemoveRe.sub(&#34;&#34;, text)
    text = tokenKeepRe.sub(&#34;&#34;, text)
    text = tokenRemoveRe.sub(&#34;&#34;, text)
    text = modelKeepRe.sub(&#34;&#34;, text)
    text = modelRemoveRe.sub(&#34;&#34;, text)
    text = slotKeepRe.sub(&#34;&#34;, text)
    text = slotRemoveRe.sub(&#34;&#34;, text)
    text = extraKeepRe.sub(&#34;&#34;, text)
    text = extraRemoveRe.sub(&#34;&#34;, text)
    text = procinsKeepRe.sub(&#34;&#34;, text)
    text = procinsRemoveRe.sub(&#34;&#34;, text)

    text = skipVars.sub(&#34;&#34;, text)

    if extra:
        text += dedent(
            f&#34;&#34;&#34;
            # Additional features

            {extra}
            &#34;&#34;&#34;
        )

    return text


def lookupSource(cv, cur, tokenAsSlot, specs):
    &#34;&#34;&#34;Looks up information from the current XML stack.

    The current XML stack contains the ancestry of the current node, including
    the current node itself.

    It is a list of components, corresponding to the path from the root node to the
    current node.
    Each component is a tuple, consisting of the tag name and the attributes of
    an XML node.

    Against this stack a sequence of instructions, given in `specs`, is executed.
    These instructions collect information from the stack, under certain conditions,
    and put that information into a feature, as value for a certain node.

    Here is an example of a single instruction:

    Parameters
    ----------
    cv: object
        The converter object, needed to issue actions.
    cur: dict
        Various pieces of data collected during walking
        and relevant for some next steps in the walk.
    specs: tuple
        A sequence of instructions what to look for.
        Each instruction has the following parts:

        *   `pathSpec`
        *   `nodeType`
        *   `featureName`

        The effect is:

        The `pathSpec` is compared to the current XML stack.
        If it matches the current node, the text content of the current node or one of
        its attributes will be collected and put in a feature with name
        `featureName`, for the current TF node of type `nodeType`.

        The `pathSpec` is a list of components.
        The first component should match the top of the XML stack, the second
        component the element that is below the top, etc.
        Each component is a tuple of

        *   a tag name;
        *   a dictionary of attribute values;

        The first component may have a tag name that has `@` plus an attribute name
        appended to it. That means that the information will be extracted from
        that attribute, not from the content of the element.
        If the attribute is not present, no feature value will be created.
    &#34;&#34;&#34;
    nest = cur[XNEST]
    nNest = len(nest)

    for path, nodeType, feature in specs:
        nPath = len(path)

        if nPath &gt; nNest:
            continue

        ok = True
        extractAttr = None

        for p, (lookForTag, lookForAtts) in enumerate(path):
            (compareToTag, compareToAtts) = nest[-(p + 1)]

            if p == 0:
                pieces = lookForTag.split(&#34;@&#34;, 1)
                if len(pieces) == 2:
                    (lookForTag, extractAttr) = pieces
                else:
                    extractAttr = None

            ok = compareToTag == lookForTag

            if not ok:
                break

            if lookForAtts is not None:
                for att, val in lookForAtts.items():
                    if att not in compareToAtts or compareToAtts[att] != val:
                        ok = False
                        break

            if not ok:
                break

        if not ok:
            continue

        targetNode = cur[NODE].get(nodeType, None)

        if targetNode is None:
            return

        sourceNode = cur[TNEST][-1]
        slots = cv.linked(sourceNode)

        skip = False

        if extractAttr is None:
            sourceText = (
                &#34;&#34;.join(
                    cv.get(&#34;str&#34;, (T, slot)) + cv.get(&#34;after&#34;, (T, slot))
                    for slot in slots
                )
                if tokenAsSlot
                else &#34;&#34;.join(cv.get(&#34;ch&#34;, (CHAR, slot)) for slot in slots)
            )
        else:
            if extractAttr.isdecimal():
                sourceText = int(extractAttr)
            else:
                if extractAttr.startswith(&#34;&lt;&#34;) and extractAttr.endswith(&#34;&gt;&#34;):
                    sourceText = extractAttr[1:-1]
                else:
                    sourceText = cv.get(extractAttr, sourceNode)

                    if sourceText is None:
                        skip = True
                    else:
                        sourceText = sourceText.strip()

        if not skip:
            source = {feature: sourceText}
            cv.feature(targetNode, **source)


def getPageInfo(pageInfoDir, zoneBased, manifestLevel):
    if pageInfoDir is None:
        return {}

    pageInfoFile = f&#34;{pageInfoDir}/pageseq.json&#34;
    facsFile = f&#34;{pageInfoDir}/facs.yml&#34;

    pages = None

    if fileExists(pageInfoFile):
        console(f&#34;Using page info file {pageInfoFile}&#34;)
        pages = readJson(asFile=pageInfoFile, plain=True)
    elif fileExists(facsFile):
        console(f&#34;Using facs file info file {facsFile}&#34;)
        pagesProto = readYaml(asFile=facsFile, plain=True, preferTuples=False)
        pages = {}

        if zoneBased:
            facsMappingFile = f&#34;{pageInfoDir}/facsMapping.yml&#34;

            if fileExists(facsMappingFile):
                console(f&#34;Using facs mapping file {facsMappingFile}&#34;)
                facsMapping = readYaml(
                    asFile=facsMappingFile, plain=True, preferTuples=False
                )

                for path, ps in pagesProto.items():
                    pathComps = path.split(&#34;/&#34;)
                    folder = pathComps[0]

                    if manifestLevel == &#34;file&#34;:
                        file = stripExt(pathComps[1])

                    mapping = facsMapping.get(path, {})
                    mappedPs = [mapping.get(p, p) for p in ps]
                    pagesDest = pages.setdefault(
                        folder, [] if manifestLevel == &#34;folder&#34; else {}
                    )

                    if manifestLevel == &#34;folder&#34;:
                        pagesDest.extend(mappedPs)
                    else:
                        pagesDest.setdefault(file, []).extend(mappedPs)
            else:
                console(f&#34;No facs mapping file {facsMappingFile}&#34;, error=True)
        else:
            for path, ps in pagesProto.items():
                (folder, file) = path.split(&#34;/&#34;)
                file = stripExt(file)
                pagesDest = pages.setdefault(
                    folder, [] if manifestLevel == &#34;folder&#34; else {}
                )
                pages.setdefault(folder, []).extend(ps)

                if manifestLevel == &#34;folder&#34;:
                    pagesDest.extend(ps)
                else:
                    pagesDest.setdefault(file, []).extend(ps)
    else:
        console(&#34;No page-facsimile relating information found&#34;, error=True)

    if pages is None:
        console(&#34;Could not assemble page sequence info&#34;, error=True)
        result = {}
    else:
        result = dict(pages=pages)

    return result


def getImageSizes(scanRefDir, doCovers, silent):
    sizeInfo = {}

    for kind in (&#34;covers&#34;, &#34;pages&#34;) if doCovers else (&#34;pages&#34;,):
        sizeFile = f&#34;{scanRefDir}/sizes_{kind}.tsv&#34;

        thisSizeInfo = {}
        sizeInfo[kind] = thisSizeInfo

        maxW, maxH = 0, 0

        n = 0

        totW, totH = 0, 0

        ws, hs = [], []

        if not fileExists(sizeFile):
            console(f&#34;Size file not found: {sizeFile}&#34;, error=True)
            continue

        with fileOpen(sizeFile) as rh:
            next(rh)
            for line in rh:
                fields = line.rstrip(&#34;\n&#34;).split(&#34;\t&#34;)
                p = fields[0]
                (w, h) = (int(x) for x in fields[1:3])
                thisSizeInfo[p] = (w, h)
                ws.append(w)
                hs.append(h)
                n += 1
                totW += w
                totH += h

                if w &gt; maxW:
                    maxW = w
                if h &gt; maxH:
                    maxH = h

        avW = int(round(totW / n))
        avH = int(round(totH / n))

        devW = int(round(sum(abs(w - avW) for w in ws) / n))
        devH = int(round(sum(abs(h - avH) for h in hs) / n))

        if not silent:
            console(f&#34;Maximum dimensions: W = {maxW:&gt;4} H = {maxH:&gt;4}&#34;)
            console(f&#34;Average dimensions: W = {avW:&gt;4} H = {avH:&gt;4}&#34;)
            console(f&#34;Average deviation:  W = {devW:&gt;4} H = {devH:&gt;4}&#34;)

    return sizeInfo


def getImageLocations(app, prod, silent):
    repoLocation = app.repoLocation
    scanDir = f&#34;{repoLocation}/scans&#34;
    thumbDir = f&#34;{repoLocation}/{app.context.provenanceSpec[&#39;graphicsRelative&#39;]}&#34;
    scanRefDir = thumbDir if prod == &#34;dev&#34; else scanDir
    coversDir = f&#34;{scanRefDir}/covers&#34;

    if dirExists(coversDir):
        if not silent:
            console(f&#34;Found covers in directory: {coversDir}&#34;)

        doCovers = True
    else:
        if not silent:
            console(f&#34;No cover directory: {coversDir}&#34;)

        doCovers = False

    return AttrDict(
        repoLocation=repoLocation,
        scanDir=scanDir,
        thumbDir=thumbDir,
        scanRefDir=scanRefDir,
        coversDir=coversDir,
        doCovers=doCovers,
    )</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="tff.convert.helpers.CM_LIT"><code class="name">var <span class="ident">CM_LIT</span></code></dt>
<dd>
<div class="desc"><p>The value is taken literally from a TEI attribute.</p>
<p>Code <code>tei</code>, since there is a 1-1 correspondence with the TEI source.</p></div>
</dd>
<dt id="tff.convert.helpers.CM_LITC"><code class="name">var <span class="ident">CM_LITC</span></code></dt>
<dd>
<div class="desc"><p>The value is results from more intricate processing of material in the TEI.</p>
<p><em>More intricate means</em>: we derive data that goes beyond pure XML syntax.</p>
<p>Examples:</p>
<ul>
<li>The values of the <code>rend</code> attributes are translated into <code>rend_</code><em>value</em> features;</li>
<li>Adding features <code>is_meta</code> (being inside the TEI-header) and <code>is_note</code>
(being inside a note);</li>
<li>The feature that gives the content of a (character) slot;</li>
<li>Decomposing strings into words material and after-word material.</li>
</ul>
<p>Code <code>tf</code>, since this is for the benefit of the resulting TF dataset.</p></div>
</dd>
<dt id="tff.convert.helpers.CM_LITP"><code class="name">var <span class="ident">CM_LITP</span></code></dt>
<dd>
<div class="desc"><p>The value results from straightforward processing of material in the TEI.</p>
<p>Code <code>tei</code>, since there is a direct correspondence with the TEI source.</p>
<p><em>Straightforward</em> means: by taking into account the semantics of XML.</p>
<p>Examples:</p>
<ul>
<li>Generated white-space based on whether elements are pure or mixed;</li>
<li>Edges between parent and child elements, or sibling elements.</li>
</ul></div>
</dd>
<dt id="tff.convert.helpers.CM_NLP"><code class="name">var <span class="ident">CM_NLP</span></code></dt>
<dd>
<div class="desc"><p>The value is added by an NLP pipeline w.r.t. the material in the TEI.</p>
<p>Code <code>nlp</code>, since this comes from third party software.</p>
<p>Examples:</p>
<ul>
<li>The feature <code>nsent</code> which gives the sentence number in the corpus.
Sentences are not encoded in the TEI, but detected by an NLP program such as Spacy.</li>
</ul></div>
</dd>
<dt id="tff.convert.helpers.CM_PROV"><code class="name">var <span class="ident">CM_PROV</span></code></dt>
<dd>
<div class="desc"><p>The value is added by the conversion to TF w.r.t. the material in the TEI.</p>
<p>Examples:</p>
<ul>
<li>Slots in empty elements, in order to anchor the element to the text sequence;</li>
<li>Section levels, based on the folder and file that the TEI source is in;</li>
<li>A section level within the TEI, defined from several elements and the way they
are nested;</li>
</ul>
<p>Code <code>tf</code>, since this is for the benefit of the resulting TF dataset.</p></div>
</dd>
<dt id="tff.convert.helpers.CONVERSION_METHODS"><code class="name">var <span class="ident">CONVERSION_METHODS</span></code></dt>
<dd>
<div class="desc"><p>Information about the conversion.</p>
<p>When we produce TF features, we specify a bit of information in the feature
metadata as how we arrived at the specific value.</p>
<p>That information ends up in two keys:</p>
<ul>
<li><code>conversionMethod</code>: with values any of:<ul>
<li><code><a title="tff.convert.helpers.CM_LIT" href="#tff.convert.helpers.CM_LIT">CM_LIT</a></code></li>
<li><code><a title="tff.convert.helpers.CM_LITP" href="#tff.convert.helpers.CM_LITP">CM_LITP</a></code></li>
<li><code><a title="tff.convert.helpers.CM_LITC" href="#tff.convert.helpers.CM_LITC">CM_LITC</a></code></li>
<li><code><a title="tff.convert.helpers.CM_PROV" href="#tff.convert.helpers.CM_PROV">CM_PROV</a></code></li>
<li><code><a title="tff.convert.helpers.CM_NLP" href="#tff.convert.helpers.CM_NLP">CM_NLP</a></code></li>
</ul>
</li>
<li>
<p><code>conversionCode</code>: the value is derived from <code>conversionMethod</code> by looking it
up in this table. These values can be used to qualify the name of the attribute
for further processing.</p>
<p>For example, if you have a feature <code>n</code> that originates literally from the TEI,
you could pass it on as <code>tei:n</code>.</p>
<p>But if you have a feature <code>chapter</code> that is provided by the conversion,
you could pass it on as <code>tf:chapter</code>.</p>
<p>This passing on is a matter of other software, that takes the generated TF as
input and processes it further, e.g. as annotations.</p>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">More methods and codes</p>
</div>
<p>The TEI conversion is customizable by providing your own methods to several hooks
in the program. These hooks may generate extra features, which you can give metadata
in the <code>config/tei.yml</code> file close to the <code>programs/tei.py</code> file where you
define the custom functions.</p>
<p>It is advised to state appropriate values for the <code>conversionMethod</code> and
<code>conversionCode</code> fields of these features.</p>
<p>Examples:</p>
<ul>
<li>
<p>A feature <code>country</code> is derived from specific elements in the TEI Header, and
defined for nodes of type <code>letter</code>.
This happens in order to support the software of Team Text that shows the
text on a webpage.</p>
<p>In such a case you could define</p>
<ul>
<li>`conversionMethod="derived"</li>
<li>`conversionCode="tt"</li>
</ul>
</li>
</ul></div>
</dd>
<dt id="tff.convert.helpers.SECTION_MODELS"><code class="name">var <span class="ident">SECTION_MODELS</span></code></dt>
<dd>
<div class="desc"><p>Models for sections.</p>
<p>A section is a part of the corpus that is defined by a set of files,
or by elements within a single TEI source file.</p>
<p>A model</p></div>
</dd>
<dt id="tff.convert.helpers.SECTION_MODEL_DEFAULT"><code class="name">var <span class="ident">SECTION_MODEL_DEFAULT</span></code></dt>
<dd>
<div class="desc"><p>Default model for sections.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tff.convert.helpers.checkModel"><code class="name flex">
<span>def <span class="ident">checkModel</span></span>(<span>kind, thisModel, verbose)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L265-L340" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def checkModel(kind, thisModel, verbose):
    modelDefault = (
        LINE_MODEL_DEFAULT
        if kind == LINE
        else PAGE_MODEL_DEFAULT if kind == PAGE else SECTION_MODEL_DEFAULT
    )
    modelSpecs = (
        LINE_MODELS if kind == LINE else PAGE_MODELS if kind == PAGE else SECTION_MODELS
    )

    if thisModel is None:
        model = modelDefault
        if verbose == 1:
            console(f&#34;WARNING: No {kind} model specified. Assuming model {model}.&#34;)
        properties = {k: v[1] for (k, v) in modelSpecs[model].items()}
        return dict(model=model, properties=properties)

    if type(thisModel) is str:
        if thisModel in modelSpecs:
            thisModel = dict(model=thisModel)
        else:
            console(f&#34;ERROR: unknown {kind} model: {thisModel}&#34;)
            return False

    elif type(thisModel) is not dict:
        console(f&#34;ERROR: {kind} model must be a dict. You passed a {type(thisModel)}&#34;)
        return False

    model = thisModel.get(&#34;model&#34;, None)

    if model is None:
        model = modelDefault
        if verbose == 1:
            console(f&#34;WARNING: No {kind} model specified. Assuming model {model}.&#34;)
        thisModel[&#34;model&#34;] = model

    if model not in modelSpecs:
        console(f&#34;WARNING: unknown {kind} model: {thisModel}&#34;)
        return False

    if verbose &gt;= 0:
        console(f&#34;{kind} model is {model}&#34;)

    properties = {k: v for (k, v) in thisModel.items() if k != &#34;model&#34;}
    modelProperties = modelSpecs[model]

    good = True
    delKeys = []

    for k, v in properties.items():
        if k not in modelProperties:
            console(f&#34;WARNING: ignoring unknown {kind} model property {k}={v}&#34;)
            delKeys.append(k)
        elif type(v) is not modelProperties[k][0]:
            console(
                f&#34;ERROR: {kind} property {k} should have type {modelProperties[k][0]}&#34;
                f&#34; but {v} has type {type(v)}&#34;
            )
            good = False
    if good:
        for k in delKeys:
            del properties[k]

    for k, v in modelProperties.items():
        if k not in properties:
            if verbose == 1:
                console(
                    f&#34;WARNING: {kind} model property {k} not specified, &#34;
                    f&#34;taking default {v[1]}&#34;
                )
            properties[k] = v[1]

    if not good:
        return False

    return dict(model=model, properties=properties)</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.getImageLocations"><code class="name flex">
<span>def <span class="ident">getImageLocations</span></span>(<span>app, prod, silent)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L858-L883" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def getImageLocations(app, prod, silent):
    repoLocation = app.repoLocation
    scanDir = f&#34;{repoLocation}/scans&#34;
    thumbDir = f&#34;{repoLocation}/{app.context.provenanceSpec[&#39;graphicsRelative&#39;]}&#34;
    scanRefDir = thumbDir if prod == &#34;dev&#34; else scanDir
    coversDir = f&#34;{scanRefDir}/covers&#34;

    if dirExists(coversDir):
        if not silent:
            console(f&#34;Found covers in directory: {coversDir}&#34;)

        doCovers = True
    else:
        if not silent:
            console(f&#34;No cover directory: {coversDir}&#34;)

        doCovers = False

    return AttrDict(
        repoLocation=repoLocation,
        scanDir=scanDir,
        thumbDir=thumbDir,
        scanRefDir=scanRefDir,
        coversDir=coversDir,
        doCovers=doCovers,
    )</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.getImageSizes"><code class="name flex">
<span>def <span class="ident">getImageSizes</span></span>(<span>scanRefDir, doCovers, silent)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L805-L855" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def getImageSizes(scanRefDir, doCovers, silent):
    sizeInfo = {}

    for kind in (&#34;covers&#34;, &#34;pages&#34;) if doCovers else (&#34;pages&#34;,):
        sizeFile = f&#34;{scanRefDir}/sizes_{kind}.tsv&#34;

        thisSizeInfo = {}
        sizeInfo[kind] = thisSizeInfo

        maxW, maxH = 0, 0

        n = 0

        totW, totH = 0, 0

        ws, hs = [], []

        if not fileExists(sizeFile):
            console(f&#34;Size file not found: {sizeFile}&#34;, error=True)
            continue

        with fileOpen(sizeFile) as rh:
            next(rh)
            for line in rh:
                fields = line.rstrip(&#34;\n&#34;).split(&#34;\t&#34;)
                p = fields[0]
                (w, h) = (int(x) for x in fields[1:3])
                thisSizeInfo[p] = (w, h)
                ws.append(w)
                hs.append(h)
                n += 1
                totW += w
                totH += h

                if w &gt; maxW:
                    maxW = w
                if h &gt; maxH:
                    maxH = h

        avW = int(round(totW / n))
        avH = int(round(totH / n))

        devW = int(round(sum(abs(w - avW) for w in ws) / n))
        devH = int(round(sum(abs(h - avH) for h in hs) / n))

        if not silent:
            console(f&#34;Maximum dimensions: W = {maxW:&gt;4} H = {maxH:&gt;4}&#34;)
            console(f&#34;Average dimensions: W = {avW:&gt;4} H = {avH:&gt;4}&#34;)
            console(f&#34;Average deviation:  W = {devW:&gt;4} H = {devH:&gt;4}&#34;)

    return sizeInfo</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.getPageInfo"><code class="name flex">
<span>def <span class="ident">getPageInfo</span></span>(<span>pageInfoDir, zoneBased, manifestLevel)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L735-L802" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def getPageInfo(pageInfoDir, zoneBased, manifestLevel):
    if pageInfoDir is None:
        return {}

    pageInfoFile = f&#34;{pageInfoDir}/pageseq.json&#34;
    facsFile = f&#34;{pageInfoDir}/facs.yml&#34;

    pages = None

    if fileExists(pageInfoFile):
        console(f&#34;Using page info file {pageInfoFile}&#34;)
        pages = readJson(asFile=pageInfoFile, plain=True)
    elif fileExists(facsFile):
        console(f&#34;Using facs file info file {facsFile}&#34;)
        pagesProto = readYaml(asFile=facsFile, plain=True, preferTuples=False)
        pages = {}

        if zoneBased:
            facsMappingFile = f&#34;{pageInfoDir}/facsMapping.yml&#34;

            if fileExists(facsMappingFile):
                console(f&#34;Using facs mapping file {facsMappingFile}&#34;)
                facsMapping = readYaml(
                    asFile=facsMappingFile, plain=True, preferTuples=False
                )

                for path, ps in pagesProto.items():
                    pathComps = path.split(&#34;/&#34;)
                    folder = pathComps[0]

                    if manifestLevel == &#34;file&#34;:
                        file = stripExt(pathComps[1])

                    mapping = facsMapping.get(path, {})
                    mappedPs = [mapping.get(p, p) for p in ps]
                    pagesDest = pages.setdefault(
                        folder, [] if manifestLevel == &#34;folder&#34; else {}
                    )

                    if manifestLevel == &#34;folder&#34;:
                        pagesDest.extend(mappedPs)
                    else:
                        pagesDest.setdefault(file, []).extend(mappedPs)
            else:
                console(f&#34;No facs mapping file {facsMappingFile}&#34;, error=True)
        else:
            for path, ps in pagesProto.items():
                (folder, file) = path.split(&#34;/&#34;)
                file = stripExt(file)
                pagesDest = pages.setdefault(
                    folder, [] if manifestLevel == &#34;folder&#34; else {}
                )
                pages.setdefault(folder, []).extend(ps)

                if manifestLevel == &#34;folder&#34;:
                    pagesDest.extend(ps)
                else:
                    pagesDest.setdefault(file, []).extend(ps)
    else:
        console(&#34;No page-facsimile relating information found&#34;, error=True)

    if pages is None:
        console(&#34;Could not assemble page sequence info&#34;, error=True)
        result = {}
    else:
        result = dict(pages=pages)

    return result</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.getWhites"><code class="name flex">
<span>def <span class="ident">getWhites</span></span>(<span>text)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L222-L237" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def getWhites(text):
    match = W_BEFORE.match(text)
    if match:
        before = match.group(0)
        rest = text[len(before) :]
    else:
        before = &#34;&#34;
        rest = text
    match = W_AFTER.search(rest)
    if match:
        after = match.group(0)
        material = rest[0 : -len(after)]
    else:
        after = &#34;&#34;
        material = rest
    return (&#34; &#34; if before else &#34;&#34;, material, &#34; &#34; if after else &#34;&#34;)</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.lookupSource"><code class="name flex">
<span>def <span class="ident">lookupSource</span></span>(<span>cv, cur, tokenAsSlot, specs)</span>
</code></dt>
<dd>
<div class="desc"><p>Looks up information from the current XML stack.</p>
<p>The current XML stack contains the ancestry of the current node, including
the current node itself.</p>
<p>It is a list of components, corresponding to the path from the root node to the
current node.
Each component is a tuple, consisting of the tag name and the attributes of
an XML node.</p>
<p>Against this stack a sequence of instructions, given in <code>specs</code>, is executed.
These instructions collect information from the stack, under certain conditions,
and put that information into a feature, as value for a certain node.</p>
<p>Here is an example of a single instruction:</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cv</code></strong> :&ensp;<code>object</code></dt>
<dd>The converter object, needed to issue actions.</dd>
<dt><strong><code>cur</code></strong> :&ensp;<code>dict</code></dt>
<dd>Various pieces of data collected during walking
and relevant for some next steps in the walk.</dd>
<dt><strong><code>specs</code></strong> :&ensp;<code>tuple</code></dt>
<dd>
<p>A sequence of instructions what to look for.
Each instruction has the following parts:</p>
<ul>
<li><code>pathSpec</code></li>
<li><code>nodeType</code></li>
<li><code>featureName</code></li>
</ul>
<p>The effect is:</p>
<p>The <code>pathSpec</code> is compared to the current XML stack.
If it matches the current node, the text content of the current node or one of
its attributes will be collected and put in a feature with name
<code>featureName</code>, for the current TF node of type <code>nodeType</code>.</p>
<p>The <code>pathSpec</code> is a list of components.
The first component should match the top of the XML stack, the second
component the element that is below the top, etc.
Each component is a tuple of</p>
<ul>
<li>a tag name;</li>
<li>a dictionary of attribute values;</li>
</ul>
<p>The first component may have a tag name that has <code>@</code> plus an attribute name
appended to it. That means that the information will be extracted from
that attribute, not from the content of the element.
If the attribute is not present, no feature value will be created.</p>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L606-L732" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def lookupSource(cv, cur, tokenAsSlot, specs):
    &#34;&#34;&#34;Looks up information from the current XML stack.

    The current XML stack contains the ancestry of the current node, including
    the current node itself.

    It is a list of components, corresponding to the path from the root node to the
    current node.
    Each component is a tuple, consisting of the tag name and the attributes of
    an XML node.

    Against this stack a sequence of instructions, given in `specs`, is executed.
    These instructions collect information from the stack, under certain conditions,
    and put that information into a feature, as value for a certain node.

    Here is an example of a single instruction:

    Parameters
    ----------
    cv: object
        The converter object, needed to issue actions.
    cur: dict
        Various pieces of data collected during walking
        and relevant for some next steps in the walk.
    specs: tuple
        A sequence of instructions what to look for.
        Each instruction has the following parts:

        *   `pathSpec`
        *   `nodeType`
        *   `featureName`

        The effect is:

        The `pathSpec` is compared to the current XML stack.
        If it matches the current node, the text content of the current node or one of
        its attributes will be collected and put in a feature with name
        `featureName`, for the current TF node of type `nodeType`.

        The `pathSpec` is a list of components.
        The first component should match the top of the XML stack, the second
        component the element that is below the top, etc.
        Each component is a tuple of

        *   a tag name;
        *   a dictionary of attribute values;

        The first component may have a tag name that has `@` plus an attribute name
        appended to it. That means that the information will be extracted from
        that attribute, not from the content of the element.
        If the attribute is not present, no feature value will be created.
    &#34;&#34;&#34;
    nest = cur[XNEST]
    nNest = len(nest)

    for path, nodeType, feature in specs:
        nPath = len(path)

        if nPath &gt; nNest:
            continue

        ok = True
        extractAttr = None

        for p, (lookForTag, lookForAtts) in enumerate(path):
            (compareToTag, compareToAtts) = nest[-(p + 1)]

            if p == 0:
                pieces = lookForTag.split(&#34;@&#34;, 1)
                if len(pieces) == 2:
                    (lookForTag, extractAttr) = pieces
                else:
                    extractAttr = None

            ok = compareToTag == lookForTag

            if not ok:
                break

            if lookForAtts is not None:
                for att, val in lookForAtts.items():
                    if att not in compareToAtts or compareToAtts[att] != val:
                        ok = False
                        break

            if not ok:
                break

        if not ok:
            continue

        targetNode = cur[NODE].get(nodeType, None)

        if targetNode is None:
            return

        sourceNode = cur[TNEST][-1]
        slots = cv.linked(sourceNode)

        skip = False

        if extractAttr is None:
            sourceText = (
                &#34;&#34;.join(
                    cv.get(&#34;str&#34;, (T, slot)) + cv.get(&#34;after&#34;, (T, slot))
                    for slot in slots
                )
                if tokenAsSlot
                else &#34;&#34;.join(cv.get(&#34;ch&#34;, (CHAR, slot)) for slot in slots)
            )
        else:
            if extractAttr.isdecimal():
                sourceText = int(extractAttr)
            else:
                if extractAttr.startswith(&#34;&lt;&#34;) and extractAttr.endswith(&#34;&gt;&#34;):
                    sourceText = extractAttr[1:-1]
                else:
                    sourceText = cv.get(extractAttr, sourceNode)

                    if sourceText is None:
                        skip = True
                    else:
                        sourceText = sourceText.strip()

        if not skip:
            source = {feature: sourceText}
            cv.feature(targetNode, **source)</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.matchModel"><code class="name flex">
<span>def <span class="ident">matchModel</span></span>(<span>properties, tag, atts)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L343-L359" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def matchModel(properties, tag, atts):
    if tag == properties[&#34;element&#34;]:
        criticalAtts = properties[&#34;attributes&#34;]
        match = True

        for k, cVal in criticalAtts.items():
            aVal = atts.get(k, None)

            thisNoMatch = (
                all(aVal != cV for cV in cVal)
                if type(cVal) in {list, tuple, set}
                else aVal != cVal
            )
            if thisNoMatch:
                match = False
                break
        return match</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.repTokens"><code class="name flex">
<span>def <span class="ident">repTokens</span></span>(<span>tokens)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L258-L262" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def repTokens(tokens):
    text = []
    for t, space in tokens:
        text.append(f&#34;‹{t}›{space}&#34;)
    return &#34;&#34;.join(text)</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.setUp"><code class="name flex">
<span>def <span class="ident">setUp</span></span>(<span>kind)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L362-L413" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def setUp(kind):
    helpText = f&#34;&#34;&#34;
    Convert {kind} to TF.

    There are also commands to check the {kind} and to load the resulting TF.&#34;&#34;&#34;

    taskSpec = dict(
        check=&#34;reports on the elements in the source&#34;,
        convert=f&#34;converts {kind} to TF&#34;,
        load=&#34;loads the generated TF&#34;,
        app=&#34;configures the TF app for the result&#34;,
        apptoken=&#34;modifies the TF app to make it token- instead of character-based&#34;,
        browse=&#34;starts the TF browser on the result&#34;,
    )

    paramSpec = {
        &#34;tf&#34;: (
            (
                &#34;0 or latest: update latest version;\n\t\t&#34;
                &#34;1 2 3: increase major, intermediate, minor TF version;\n\t\t&#34;
                &#34;rest: explicit version.&#34;
            ),
            &#34;latest&#34;,
        ),
        &#34;sourceBase&#34;: (
            (&#34;empty: refDir/{kind.lower()};\n\t\t&#34; &#34;any directory of choice.&#34;),
            &#34;&#34;,
        ),
        &#34;reportDir&#34;: (
            (&#34;empty: refDir/report;\n\t\t&#34; &#34;any directory of choice.&#34;),
            &#34;&#34;,
        ),
        kind.lower(): (
            (
                &#34;0 or latest: latest version;\n\t\t&#34;
                &#34;-1 -2 etc: previous version, before previous, ...;\n\t\t&#34;
                &#34;1 2 etc: first version, second version, ...;\n\t\t&#34;
                &#34;rest: explicit version.&#34;
            ),
            &#34;latest&#34;,
        ),
        &#34;validate&#34;: (
            &#34;Whether to validate the XML input&#34;,
            True,
        ),
    }

    flagSpec = dict(
        verbose=(&#34;Produce less or more progress and reporting messages&#34;, -1, 3),
        doc=(&#34;Do only this document&#34;, None, 0),
    )
    return (helpText, taskSpec, paramSpec, flagSpec)</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.tokenize"><code class="name flex">
<span>def <span class="ident">tokenize</span></span>(<span>line)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L240-L255" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tokenize(line):
    tokens = []

    for word in line.split():
        ts = (
            [[word, &#34;&#34;]]
            if NUMBER_RE.match(word)
            else [[t, &#34;&#34;] for t in TOKEN_RE.findall(word)]
        )
        if len(ts):
            ts[-1][-1] = &#34; &#34;
        tokens.extend(ts)

    if len(tokens):
        tokens[-1][-1] = &#34;&#34;
    return tuple(tokens)</code></pre>
</details>
</dd>
<dt id="tff.convert.helpers.tweakTrans"><code class="name flex">
<span>def <span class="ident">tweakTrans</span></span>(<span>template, procins, wordAsSlot, tokenAsSlot, charAsSlot, parentEdges, siblingEdges, tokenBased, sectionModel, sectionProperties, rendDesc, extra)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric-factory/blob/87a5452921d16a1d54c01fbf7831c3c5cafce013/tff/convert/helpers.py#L416-L603" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tweakTrans(
    template,
    procins,
    wordAsSlot,
    tokenAsSlot,
    charAsSlot,
    parentEdges,
    siblingEdges,
    tokenBased,
    sectionModel,
    sectionProperties,
    rendDesc,
    extra,
):
    if wordAsSlot:
        slot = WORD
        slotc = &#34;Word&#34;
        slotf = &#34;words&#34;
        xslot = &#34;`word`&#34;
    elif charAsSlot:
        slotc = &#34;Char&#34;
        slot = CHAR
        slotf = &#34;characters&#34;
        xslot = &#34;`char` and `word`&#34;
    elif tokenAsSlot or True:
        slotc = &#34;Token&#34;
        slot = T
        slotf = &#34;tokens&#34;
        xslot = &#34;`t` and `word`&#34;

    if parentEdges:
        hasParent = &#34;Yes&#34;
    else:
        hasParent = &#34;No&#34;

    if siblingEdges:
        hasSibling = &#34;Yes&#34;
    else:
        hasSibling = &#34;No&#34;

    if tokenBased:
        slot = TOKEN
        slotc = &#34;Token&#34;
        slotf = &#34;tokens&#34;
        xslot = &#34;`token`&#34;
        tokenGen = dedent(
            &#34;&#34;&#34;
            Tokens and sentence boundaries have been generated by a Natural Language
            Pipeline, such as Spacy.
            &#34;&#34;&#34;
        )
        tokenWord = &#34;token&#34;
        hasToken = &#34;Yes&#34;
    else:
        tokenGen = &#34;&#34;
        tokenWord = &#34;word&#34;
        hasToken = &#34;No&#34;

    if extra:
        hasExtra = &#34;Yes&#34;
    else:
        hasExtra = &#34;No&#34;

    if procins:
        doProcins = &#34;Yes&#34;
    else:
        doProcins = &#34;No&#34;

    levelNames = sectionProperties[&#34;levels&#34;]

    if sectionModel == &#34;II&#34;:
        nLevels = &#34;2&#34;
        chapterSection = levelNames[0]
        chunkSection = levelNames[1]
        head = sectionProperties[&#34;element&#34;]
        attributes = sectionProperties[&#34;attributes&#34;]
        propertiesRaw = repr(sectionProperties)
        properties = (
            &#34;&#34;.join(
                f&#34;\t*\t`{att}` = `{val}`\n&#34; for (att, val) in sorted(attributes.items())
            )
            if attributes
            else &#34;\t*\t*no attribute properties*\n&#34;
        )
    elif sectionModel == &#34;III&#34;:
        nLevels = &#34;3&#34;
        fileSection = levelNames[0]
        chapterSection = levelNames[1]
        chunkSection = levelNames[2]
        head = sectionProperties[&#34;element&#34;]
        attributes = sectionProperties[&#34;attributes&#34;]
        propertiesRaw = repr(sectionProperties)
        properties = (
            &#34;&#34;.join(
                f&#34;\t*\t`{att}` = `{val}`\n&#34; for (att, val) in sorted(attributes.items())
            )
            if attributes
            else &#34;\t*\t*no attribute properties*\n&#34;
        )
    else:
        nLevels = &#34;3&#34;
        folderSection = levelNames[0]
        fileSection = levelNames[1]
        chunkSection = levelNames[2]

    rendDescStr = &#34;\n&#34;.join(
        f&#34;`{val}` | {desc}&#34; for (val, desc) in sorted(rendDesc.items())
    )
    modelKeepRe = re.compile(rf&#34;«(?:begin|end)Model{sectionModel}»&#34;)
    modelRemoveRe = re.compile(r&#34;«beginModel([^»]+)».*?«endModel\1»&#34;, re.S)
    slotKeepRe = re.compile(rf&#34;«(?:begin|end)Slot{slot}»&#34;)
    slotRemoveRe = re.compile(r&#34;«beginSlot([^»]+)».*?«endSlot\1»&#34;, re.S)
    tokenKeepRe = re.compile(rf&#34;«(?:begin|end)Token{hasToken}»&#34;)
    tokenRemoveRe = re.compile(r&#34;«beginToken([^»]+)».*?«endToken\1»&#34;, re.S)
    parentKeepRe = re.compile(rf&#34;«(?:begin|end)Parent{hasParent}»&#34;)
    parentRemoveRe = re.compile(r&#34;«beginParent([^»]+)».*?«endParent\1»&#34;, re.S)
    siblingKeepRe = re.compile(rf&#34;«(?:begin|end)Sibling{hasSibling}»&#34;)
    siblingRemoveRe = re.compile(r&#34;«beginSibling([^»]+)».*?«endSibling\1»&#34;, re.S)
    extraKeepRe = re.compile(rf&#34;«(?:begin|end)Extra{hasExtra}»&#34;)
    extraRemoveRe = re.compile(r&#34;«beginExtra([^»]+)».*?«endToken\1»&#34;, re.S)
    procinsKeepRe = re.compile(rf&#34;«(?:begin|end)Procins{doProcins}»&#34;)
    procinsRemoveRe = re.compile(r&#34;«beginProcins([^»]+)».*?«endToken\1»&#34;, re.S)

    skipVars = re.compile(r&#34;«[^»]+»&#34;)

    text = (
        template.replace(&#34;«slot»&#34;, slot)
        .replace(&#34;«Slot»&#34;, slotc)
        .replace(&#34;«slotf»&#34;, slotf)
        .replace(&#34;«char and word»&#34;, xslot)
        .replace(&#34;«tokenWord»&#34;, tokenWord)
        .replace(&#34;«token generation»&#34;, tokenGen)
        .replace(&#34;«nLevels»&#34;, nLevels)
        .replace(&#34;«sectionModel»&#34;, sectionModel)
        .replace(&#34;«rendDesc»&#34;, rendDescStr)
        .replace(&#34;«extraFeatures»&#34;, extra)
    )
    if sectionModel == &#34;II&#34;:
        text = (
            text.replace(&#34;«head»&#34;, head)
            .replace(&#34;«properties»&#34;, properties)
            .replace(&#34;«propertiesRaw»&#34;, propertiesRaw)
            .replace(&#34;«chapter»&#34;, chapterSection)
            .replace(&#34;«chunk»&#34;, chunkSection)
        )
    elif sectionModel == &#34;III&#34;:
        text = (
            text.replace(&#34;«file»&#34;, fileSection)
            .replace(&#34;«head»&#34;, head)
            .replace(&#34;«properties»&#34;, properties)
            .replace(&#34;«propertiesRaw»&#34;, propertiesRaw)
            .replace(&#34;«chapter»&#34;, chapterSection)
            .replace(&#34;«chunk»&#34;, chunkSection)
        )
    else:
        text = (
            text.replace(&#34;«folder»&#34;, folderSection)
            .replace(&#34;«file»&#34;, fileSection)
            .replace(&#34;«chunk»&#34;, chunkSection)
        )

    text = parentKeepRe.sub(&#34;&#34;, text)
    text = parentRemoveRe.sub(&#34;&#34;, text)
    text = siblingKeepRe.sub(&#34;&#34;, text)
    text = siblingRemoveRe.sub(&#34;&#34;, text)
    text = tokenKeepRe.sub(&#34;&#34;, text)
    text = tokenRemoveRe.sub(&#34;&#34;, text)
    text = modelKeepRe.sub(&#34;&#34;, text)
    text = modelRemoveRe.sub(&#34;&#34;, text)
    text = slotKeepRe.sub(&#34;&#34;, text)
    text = slotRemoveRe.sub(&#34;&#34;, text)
    text = extraKeepRe.sub(&#34;&#34;, text)
    text = extraRemoveRe.sub(&#34;&#34;, text)
    text = procinsKeepRe.sub(&#34;&#34;, text)
    text = procinsRemoveRe.sub(&#34;&#34;, text)

    text = skipVars.sub(&#34;&#34;, text)

    if extra:
        text += dedent(
            f&#34;&#34;&#34;
            # Additional features

            {extra}
            &#34;&#34;&#34;
        )

    return text</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<p><a href="https://github.com/annotation" title="annotation on GitHub"><img src="../../tff/images/tf-small.png" alt="annotation"></a></p>
<p><a href="../../tff/index.html">tff home</a> -
<a href="../../tff/cheatsheet.html">cheat sheet</a> -
<a href="https://github.com/annotation/text-fabric-factory" title="GitHub repo"><img src="../../tff/images/GitHub_Logo.png" alt="GitHub" width="50"></a></p>
</p>
<form>
<input id="lunr-search" name="q" placeholder="🔎 Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tff.convert" href="index.html">tff.convert</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="tff.convert.helpers.CM_LIT" href="#tff.convert.helpers.CM_LIT">CM_LIT</a></code></li>
<li><code><a title="tff.convert.helpers.CM_LITC" href="#tff.convert.helpers.CM_LITC">CM_LITC</a></code></li>
<li><code><a title="tff.convert.helpers.CM_LITP" href="#tff.convert.helpers.CM_LITP">CM_LITP</a></code></li>
<li><code><a title="tff.convert.helpers.CM_NLP" href="#tff.convert.helpers.CM_NLP">CM_NLP</a></code></li>
<li><code><a title="tff.convert.helpers.CM_PROV" href="#tff.convert.helpers.CM_PROV">CM_PROV</a></code></li>
<li><code><a title="tff.convert.helpers.CONVERSION_METHODS" href="#tff.convert.helpers.CONVERSION_METHODS">CONVERSION_METHODS</a></code></li>
<li><code><a title="tff.convert.helpers.SECTION_MODELS" href="#tff.convert.helpers.SECTION_MODELS">SECTION_MODELS</a></code></li>
<li><code><a title="tff.convert.helpers.SECTION_MODEL_DEFAULT" href="#tff.convert.helpers.SECTION_MODEL_DEFAULT">SECTION_MODEL_DEFAULT</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="tff.convert.helpers.checkModel" href="#tff.convert.helpers.checkModel">checkModel</a></code></li>
<li><code><a title="tff.convert.helpers.getImageLocations" href="#tff.convert.helpers.getImageLocations">getImageLocations</a></code></li>
<li><code><a title="tff.convert.helpers.getImageSizes" href="#tff.convert.helpers.getImageSizes">getImageSizes</a></code></li>
<li><code><a title="tff.convert.helpers.getPageInfo" href="#tff.convert.helpers.getPageInfo">getPageInfo</a></code></li>
<li><code><a title="tff.convert.helpers.getWhites" href="#tff.convert.helpers.getWhites">getWhites</a></code></li>
<li><code><a title="tff.convert.helpers.lookupSource" href="#tff.convert.helpers.lookupSource">lookupSource</a></code></li>
<li><code><a title="tff.convert.helpers.matchModel" href="#tff.convert.helpers.matchModel">matchModel</a></code></li>
<li><code><a title="tff.convert.helpers.repTokens" href="#tff.convert.helpers.repTokens">repTokens</a></code></li>
<li><code><a title="tff.convert.helpers.setUp" href="#tff.convert.helpers.setUp">setUp</a></code></li>
<li><code><a title="tff.convert.helpers.tokenize" href="#tff.convert.helpers.tokenize">tokenize</a></code></li>
<li><code><a title="tff.convert.helpers.tweakTrans" href="#tff.convert.helpers.tweakTrans">tweakTrans</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<a href="https://pure.knaw.nl/portal/en/persons/dirk-roorda">Dirk Roorda</a>
<a href="https://huc.knaw.nl"><img alt="HuC" src="../../tff/images/huc.png" width="200" alt="Humanities Cluster"></a>
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
